{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics \n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.utils import shuffle\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Data/Method 1 Upsampled/toRNN_Individual/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV Data...\n",
      "('Number of Stable class examples: ', 2875)\n",
      "('Numbuer of Unstable class examples: ', 2875)\n"
     ]
    }
   ],
   "source": [
    "print('Reading CSV Data...')\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "#Create a new feature for normal (non-fraudulent) transactions.\n",
    "df.loc[df.label == 0, 'Slip'] = 1\n",
    "df.loc[df.label == 1, 'Slip'] = 0\n",
    "\n",
    "\n",
    "#Rename 'Class' to 'Fraud'.\n",
    "df = df.rename(columns={'label': 'Stable'})\n",
    "\n",
    "df.Slip = df.Slip.astype(int)\n",
    "df.Stable = df.Stable.astype(int)\n",
    "\n",
    "\n",
    "Slip = df[df.Slip == 1]\n",
    "Stable = df[df.Stable == 1]\n",
    "\n",
    "#Equal number of Stable and Unstable class examples\n",
    "Stable = Stable.iloc[0:Slip.iloc[:,1].count(), :]\n",
    "\n",
    "print ('Number of Stable class examples: ', Stable.iloc[:,1].count())\n",
    "print ('Numbuer of Unstable class examples: ', Slip.iloc[:,1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of train set', 4600)\n",
      "('Length of test set', 12150)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add 80% of the slip transactions to X_train.\n",
    "X_train = Slip.sample(frac=0.8)\n",
    "count_Slip = len(X_train)\n",
    "\n",
    "# Add 80% of the stable transactions to X_train.\n",
    "X_train = pd.concat([X_train, Stable.sample(frac = 0.8)], axis = 0)\n",
    "\n",
    "# X_test contains all the transaction not in X_train.\n",
    "X_test = df.loc[~df.index.isin(X_train.index)]\n",
    "\n",
    "# Shuffle the dataframes so that the training is done in a random order.\n",
    "#X_train = shuffle(X_train)\n",
    "#X_test = shuffle(X_test)\n",
    "\n",
    "X_train = X_train.iloc[0:48600, :]\n",
    "X_test = X_test.iloc[0:12150, :]\n",
    "\n",
    "\n",
    "print ('Length of train set', len(X_train))\n",
    "print ('Length of test set', len (X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our target features to y_train and y_test.\n",
    "\n",
    "#df.loc[df.label == 0, 'Slip'] = 1\n",
    "\n",
    "y_train = pd.concat([X_train.Slip, X_train.Stable], axis=1)\n",
    "y_test = pd.concat([X_test.Slip, X_test.Stable], axis=1)\n",
    "\n",
    "# Drop target features from X_train and X_test.\n",
    "X_train = X_train.drop(['Slip', 'Stable'], axis = 1)\n",
    "X_test = X_test.drop(['Slip', 'Stable'], axis = 1)\n",
    "\n",
    "\n",
    "# Check to ensure all of the training/testing dataframes are of the correct length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(loss_list, accuracy_list):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "    plt.plot(accuracy_list)\n",
    "    \n",
    "    #for batch_series_idx in range(batch_size):\n",
    "        #one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        #single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        #plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        #plt.cla()\n",
    "        #plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        #left_offset = range(truncated_backprop_length)\n",
    "        #plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        #plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        #plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#unrolled features\n",
    "time_steps = 3 #49\n",
    "#LSTM units - features \n",
    "num_units=10\n",
    "#number of exmples in batch\n",
    "n_input=X_train.columns.size\n",
    "#learning rate for adam\n",
    "learning_rate=0.001\n",
    "n_classes=2\n",
    "#size of batch\n",
    "batch_size=30\n",
    "#truncated_backprop_length = 15\n",
    "total_series_length = len(X_train)\n",
    "\n",
    "\n",
    "num_batches = X_train.index.size//batch_size//n_input\n",
    "print(num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights and biases of appropriate shape to accomplish above task\n",
    "out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))\n",
    "out_bias=tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "#defining placeholders\n",
    "batchX_placeholder=tf.placeholder(\"float\",[None,n_input])\n",
    "#input label placeholder\n",
    "batchY_placeholder=tf.placeholder(\"float\",[None,n_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\n",
    "#input=tf.unstack(batchX_placeholder ,batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the network\n",
    "lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\n",
    "outputs,_=rnn.static_rnn(lstm_layer,[batchX_placeholder],dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\n",
    "prediction=tf.matmul(outputs[-1],out_weights)+out_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "\n",
    "#loss_function\n",
    "#loss = -tf.reduce_sum(batchY_placeholder * tf.log(prediction))\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=batchY_placeholder))\n",
    "output = tf.cast(prediction, tf.float32)\n",
    "labels = tf.cast(batchY_placeholder, tf.float32)\n",
    "\n",
    "\n",
    "#optimization\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#model evaluation\n",
    "correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(batchY_placeholder,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 10)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.20337644)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 20)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.17209759)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 30)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.14714909)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 40)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.12709193)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 50)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.1107926)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 60)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.09740372)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 70)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.086291894)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 80)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.076980174)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 90)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.069106326)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 100)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.062392183)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 110)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.05662252)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 120)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.051628593)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 130)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.047277741)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 140)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.043463655)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 150)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.040101174)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 160)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.037121419)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 170)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.03446785)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 180)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.032094132)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 190)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.029961696)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 200)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.028038682)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 210)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.026298124)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 220)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.024717245)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 230)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.023276778)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 240)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.021960422)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 250)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.020753963)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 260)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.019645406)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 270)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.018624198)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 280)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.017681239)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 290)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.016808433)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 300)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.015999153)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 310)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.015246986)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 320)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.014546769)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 330)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.013893677)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 340)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.013283329)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 350)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.012712275)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 360)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.012177053)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 370)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.011674536)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 380)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.011202179)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 390)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.010757549)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 400)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.010338443)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 410)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0099430019)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 420)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0095693693)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 430)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0092159119)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 440)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0088811154)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 450)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0085639358)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 460)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.008262855)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 470)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0079769362)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 480)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0077050161)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 490)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.007446391)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 500)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0072000092)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 510)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0069651669)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 520)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0067411615)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 530)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0065272944)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 540)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0063229753)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 550)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0061276192)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 560)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0059407568)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 570)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0057618017)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 580)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0055904007)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 590)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.005425964)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 600)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0052682613)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 610)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0051169391)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 620)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.004971642)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 630)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0048320186)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 640)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0046977145)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 650)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0045686145)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 660)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0044442457)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 670)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.004324608)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 680)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0042092311)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 690)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0040981132)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 700)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0039909021)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 710)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.003887597)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 720)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0037877259)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 730)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0036914083)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 740)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0035984069)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 750)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0035084856)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 760)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0034215259)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 770)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0033374107)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 780)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0032561398)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "('For iter ', 790)\n",
      "('Training Accuracy ', 1.0)\n",
      "('Training Loss ', 0.0031773585)\n",
      "__________________\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n",
      "2500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11751d290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)\n",
    "\n",
    "#initialize variables\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    #plt.ion()\n",
    "    #plt.figure()\n",
    "    #plt.show()\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    test_loss_list = []\n",
    "    test_acc_list = []\n",
    "    iter=1\n",
    "    while iter<800:\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            \n",
    "            #indexes for data\n",
    "            start_idx = batch_idx * n_input \n",
    "            end_idx = start_idx + n_input \n",
    "            batch_x = X_train.iloc[start_idx:end_idx, :]\n",
    "            #batch_x = np.array(batch_x)\n",
    "            #print (batch_x)\n",
    "            #batch_x=batch_x.reshape((batch_size, -1, n_input))\n",
    "            #print (batch_x)\n",
    "            #list_batch_x = list(batch_x.itertuples(index=False))\n",
    "            #batch_x = (batch_idx,list_batch_x)\n",
    "\n",
    "            \n",
    "            #TODO: replace with previous value\n",
    "            #batch_x[np.isnan(batch_x)] = 0\n",
    "\n",
    "            #indexes for labels\n",
    "            start_idx = batch_idx * n_input \n",
    "            end_idx = start_idx + n_input\n",
    "            batch_y = y_train.iloc[start_idx:end_idx, :]\n",
    "            #list_batch_y = list(batch_y.itertuples(index=False))\n",
    "            #batch_y = (batch_idx,list_batch_y)\n",
    "            #print ((batch_x.size))\n",
    "            #print (len(batch_y.columns ))\n",
    "\n",
    "            sess.run(opt, feed_dict={batchX_placeholder: batch_x, \n",
    "                                         batchY_placeholder: batch_y})\n",
    "            \n",
    "            \n",
    "            \n",
    "        if iter %10==0:\n",
    "\n",
    "            los=sess.run(loss, feed_dict={batchX_placeholder:batch_x,batchY_placeholder:batch_y})\n",
    "            acc=sess.run(accuracy, feed_dict={batchX_placeholder:batch_x,batchY_placeholder:batch_y})\n",
    "            \n",
    "            \n",
    "            loss_list.append(los)\n",
    "            acc_list.append(acc)\n",
    "            \n",
    "            #plot(loss_list, acc_list)\n",
    "            print(\"For iter \",iter)\n",
    "            print(\"Training Accuracy \",acc)\n",
    "            print(\"Training Loss \",los)\n",
    "            print(\"__________________\")\n",
    "\n",
    "        iter=iter+1\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "\n",
    "            #indexes for data\n",
    "            start_idx = batch_idx * batch_size \n",
    "            end_idx = start_idx + batch_size * n_input\n",
    "            batch_x = X_test.iloc[start_idx:end_idx, :]\n",
    "            batch_x = np.array(batch_x)\n",
    "            batch_x=batch_x.reshape((batch_size,time_steps,n_input))\n",
    "\n",
    "            batch_x[np.isnan(batch_x)] = 0\n",
    "\n",
    "            #indexes for labels\n",
    "            start_idx = batch_idx * batch_size \n",
    "            end_idx = start_idx + batch_size\n",
    "            batch_y = y_test.iloc[start_idx:end_idx, :]\n",
    "\n",
    "            test_loss=sess.run(loss, feed_dict={batchX_placeholder:batch_x,batchY_placeholder:batch_y})\n",
    "            test_acc=sess.run(accuracy, feed_dict={batchX_placeholder:batch_x,batchY_placeholder:batch_y})\n",
    "            test_loss_list.append(test_loss)\n",
    "            test_acc_list.append(test_acc)\n",
    "            #plot(loss_list, acc_list)\n",
    "            print(\"For iter \",iter)\n",
    "            print(\"Testing Accuracy \",test_acc)\n",
    "            print(\"Testing Loss \",test_los)\n",
    "            print(\"__________________\")\n",
    "            \n",
    "\n",
    "            \n",
    "    #test_acc = sess.run(accuracy, feed_dict={batchX_placeholder: X_train, batchY_placeholder: y_train})\n",
    "    \n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,4))\n",
    "\n",
    "ax1.plot(acc_list, color = 'green',  label = 'training') # green\n",
    "#ax1.plot(loss_list, color = 'orange', label = 'validation') # orange\n",
    "ax1.plot(test_acc, color = 'blue', label = 'testing') # blue\n",
    "ax1.set_title('Accuracy')\n",
    "\n",
    "\n",
    "ax2.plot(loss_list, color = 'green',  label = 'training')\n",
    "#ax2.plot(valid_cost_mean, color = 'orange', label = 'validation')\n",
    "ax2.plot(test_loss_list, color = 'blue', label = 'testing') \n",
    "ax2.set_title('Cost')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=1, borderaxespad=0.)\n",
    "plt.xlabel('Epochs (x10)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
